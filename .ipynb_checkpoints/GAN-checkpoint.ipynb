{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "IMG_SHAPE = [64, 64, 3]\n",
    "LATENT_LEN = 64\n",
    "\n",
    "TRAIN_STEPS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_nn(latent_len=LATENT_LEN):\n",
    "    latent_input = tf.keras.layers.Input([latent_len])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(4*4*64, activation='relu')(latent_input)\n",
    "    x = tf.keras.layers.Reshape([4, 4, 64])(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    image_output = tf.keras.layers.Conv2D(3, 1, padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    generator = tf.keras.Model(latent_input, image_output)\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_nn(img_shape=IMG_SHAPE):\n",
    "    image_input = tf.keras.layers.Input(img_shape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(8, 3, padding='same')(image_input)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(16, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    class_output = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    discriminator = tf.keras.Model(image_input, class_output)\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_nn()\n",
    "discriminator = discriminator_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = True\n",
    "    \n",
    "generator.trainable = False\n",
    "\n",
    "real_image = tf.keras.layers.Input(IMG_SHAPE)\n",
    "latent_input = tf.keras.layers.Input([LATENT_LEN])\n",
    "fake_image = generator(latent_input)\n",
    "\n",
    "validity_real = discriminator(real_image)\n",
    "validity_fake = discriminator(fake_image)\n",
    "\n",
    "DiscriminatorModel = tf.keras.Model([real_image, latent_input], [validity_real, validity_fake])\n",
    "\n",
    "DiscriminatorModel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0002), loss=['mean_squared_error', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "latent_input = tf.keras.layers.Input([LATENT_LEN])\n",
    "\n",
    "fake_image = generator(latent_input)\n",
    "\n",
    "validity_fake = discriminator(fake_image)\n",
    "\n",
    "GeneratorModel = tf.keras.Model(latent_input, validity_fake)\n",
    "\n",
    "GeneratorModel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0002), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N1kkQ\\anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\r",
      "  0%|                                                                                       | 0/100001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8189 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▍                    | 2047/100001 [11:41<11:53:36,  2.29it/s, iter=2046, d_loss_mean=0.0116, g_loss_mean=0.00355]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8189 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▊                   | 4094/100001 [39:47<36:53:43,  1.38s/it, iter=4093, d_loss_mean=0.00623, g_loss_mean=0.00198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8189 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▉                | 5694/100001 [1:58:49<105:40:28,  4.03s/it, iter=5693, d_loss_mean=0.00461, g_loss_mean=0.00149]"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "d_loss, g_loss = [], []\n",
    "pbar = tqdm(range(TRAIN_STEPS+1))\n",
    "\n",
    "ds_size = int(len(os.listdir('data/flowers')) / BATCH_SIZE)\n",
    "for i in pbar:\n",
    "    \n",
    "    if i % ds_size == 0:\n",
    "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            'data',\n",
    "            target_size=(IMG_SHAPE[0], IMG_SHAPE[0]),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None)\n",
    "    \n",
    "    real_labels = np.ones([BATCH_SIZE, 1])\n",
    "    fake_labels = np.zeros([BATCH_SIZE, 1])\n",
    "    \n",
    "    real_images = train_generator.next()\n",
    "    latent_vectors = np.random.normal(0.0, 1.0, [BATCH_SIZE, LATENT_LEN]).astype(np.float32)\n",
    "    \n",
    "    d_hist = DiscriminatorModel.fit([real_images, latent_vectors], [real_labels, fake_labels], verbose=0)\n",
    "    d_loss.append(d_hist.history['loss'][0])\n",
    "    \n",
    "    latent_vectors = np.random.normal(0.0, 1.0, [BATCH_SIZE, LATENT_LEN]).astype(np.float32)\n",
    "    g_hist = GeneratorModel.fit(latent_vectors, real_labels, verbose=0)\n",
    "    g_loss.append(g_hist.history['loss'][0])\n",
    "    \n",
    "    pbar.set_postfix({'iter':i, 'd_loss_mean':np.mean(d_loss), 'g_loss_mean':np.mean(g_loss)})\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        discriminator.save_weights('models/discriminator_loss {}_num_steps {}.h5'.format(str(np.mean(d_loss)), str(i)))\n",
    "        generator.save_weights('models/generator_loss {}_num_steps {}.h5'.format(str(np.mean(g_loss)), str(i)))\n",
    "    if i % 500 == 0:\n",
    "        latent_vector_test = np.random.normal(0.0, 1.0, [1, LATENT_LEN]).astype(np.float32)\n",
    "        ax.imshow(generator.predict(latent_vector_test)[0])\n",
    "        plt.savefig('images/num_steps {}.png'.format(str(i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
